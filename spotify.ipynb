{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260b8cda-7633-4946-bd08-588dec5e6d78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Project: Million Playlist Dataset\n",
    "## Spotify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde6c05-efb8-4d24-b11f-97e4181f6964",
   "metadata": {},
   "source": [
    "1. Present your approach to handling this big dataset. Given that the dataset is big, at about 35 GB,\n",
    "you are not expected to be able to process all of it. Ideally, of course, you should have a solution\n",
    "that scales to the whole dataset. Describe the approach you took and all the alternatives you\n",
    "considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d003bb4-f8d3-44f2-bc42-710cfbc47a4f",
   "metadata": {},
   "source": [
    "## A.Random selection\n",
    "Randomly, we could pick a sample of playlists.\n",
    "### Simple random selection\n",
    "1st, a random selection on the 1000 playlists groups.\n",
    "### Double random selection\n",
    "2nd, a random selection on the 1000 playlists inside the playlists groups\n",
    "\n",
    "But we could suppose the available playlists groups were already randomly build. Therefore, represent already a representative sample.\n",
    "This assumption saves a loop.\n",
    "\n",
    "## B.Stratified selection\n",
    "Another option would be to build a stratified sample, based on the playlists content, but it supposes the 1 million playlists have been crossed through once.\n",
    "Then, to create a list recording the 1 million playlists names. Based on that, we could group playlists by types, and produce some stats to build a stratified selection. \n",
    "\n",
    "## C. Strategy choice\n",
    "\n",
    "We finnaly chose the 2nd strategy: a stratified sample of the 1 million playlists, data expensive but with DASK, it should be quite fast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fb022-6fef-4654-9182-05f395618ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "799089ef-a42e-4cf3-ae16-017cc84311cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159081b9-4b39-44fb-8ae5-18bcc019ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f4539-1818-439f-88bf-29dcc80cd9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
